{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time init\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000001',\n",
       " 1: '0x21596b451da15002ebbb91661f7f5e9f2f372343000000000000000000000011',\n",
       " 2: '0xed8c4c43e03e24b7f12975472da771ce2f8b857c000000000000000000000000',\n",
       " 3: '0xbcc871dab5a507624e55afeaa93610a424c446cc000000000000000000000000',\n",
       " 4: '0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000004',\n",
       " 5: '0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000003',\n",
       " 6: '0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000002',\n",
       " 7: '0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000002',\n",
       " 8: '0x7cf40a60c390723ec2d34c2fef23314d830eed22000000000000000000000000',\n",
       " 9: '0x31307ef22c77cc89cd7e61246608f15b82d09fed000000000000000000000001',\n",
       " 10: '0xe5b451c363197d375904ec167d8ed10b7bbd1e63000000000000000000000002',\n",
       " 11: '0xe254824846257f132fdcac1115c4ca9fead4f47c000000000000000000000000'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Étape 1 : Chargement et nettoyage des données\n",
    "def load_and_clean_data(filepath):\n",
    "    # csv file to dataframe\n",
    "    file_path = \"orders.csv\"  # Remplace par le chemin réel de ton fichier\n",
    "    columns = [\"OrderHash\", \"Block\", \"Action\", \"Price\", \"Quantity\", \"OrderType\", \"SubaccountID\"]\n",
    "    df = pd.read_csv(file_path, names=columns, skiprows=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_and_clean_data(filepath=\"orders.csv\")\n",
    "data=df.copy()\n",
    "subaccounts = df[\"SubaccountID\"].unique()\n",
    "\n",
    "#match subaccount to a number\n",
    "\n",
    "subaccount_num_mapping = {idx :subaccount for idx, subaccount in enumerate(subaccounts)}\n",
    "subaccount_num_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subaccount 0 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000001):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.00\n",
      "  Marketmaker Score = 0.31\n",
      "Subaccount 1 (0x21596b451da15002ebbb91661f7f5e9f2f372343000000000000000000000011):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 1.00\n",
      "  Marketmaker Score = 0.77\n",
      "Subaccount 2 (0xed8c4c43e03e24b7f12975472da771ce2f8b857c000000000000000000000000):\n",
      "  Ratio d'annulation = 0.64\n",
      "  Symmetry Score Normalisé = 0.46\n",
      "  Marketmaker Score = 0.64\n",
      "Subaccount 3 (0xbcc871dab5a507624e55afeaa93610a424c446cc000000000000000000000000):\n",
      "  Ratio d'annulation = 1.00\n",
      "  Symmetry Score Normalisé = 0.07\n",
      "  Marketmaker Score = 0.44\n",
      "Subaccount 4 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000004):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.49\n",
      "  Marketmaker Score = 0.53\n",
      "Subaccount 5 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000003):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.21\n",
      "  Marketmaker Score = 0.29\n",
      "Subaccount 6 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000002):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.22\n",
      "  Marketmaker Score = 0.29\n",
      "Subaccount 7 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000002):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.22\n",
      "  Marketmaker Score = 0.29\n",
      "Subaccount 8 (0x7cf40a60c390723ec2d34c2fef23314d830eed22000000000000000000000000):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.21\n",
      "  Marketmaker Score = 0.29\n",
      "Subaccount 9 (0x31307ef22c77cc89cd7e61246608f15b82d09fed000000000000000000000001):\n",
      "  Ratio d'annulation = 0.50\n",
      "  Symmetry Score Normalisé = 0.10\n",
      "  Marketmaker Score = 0.25\n",
      "Subaccount 10 (0xe5b451c363197d375904ec167d8ed10b7bbd1e63000000000000000000000002):\n",
      "  Ratio d'annulation = 1.00\n",
      "  Symmetry Score Normalisé = 0.14\n",
      "  Marketmaker Score = 0.46\n",
      "Subaccount 11 (0xe254824846257f132fdcac1115c4ca9fead4f47c000000000000000000000000):\n",
      "  Ratio d'annulation = 1.00\n",
      "  Symmetry Score Normalisé = 0.22\n",
      "  Marketmaker Score = 0.49\n",
      "Marketmaker #1: Subaccount 1 (0x21596b451da15002ebbb91661f7f5e9f2f372343000000000000000000000011) with Marketmaker Score = 0.77\n",
      "Marketmaker #2: Subaccount 2 (0xed8c4c43e03e24b7f12975472da771ce2f8b857c000000000000000000000000) with Marketmaker Score = 0.64\n"
     ]
    }
   ],
   "source": [
    "#IDENTIFY MARKETMAKERS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialiser les listes pour les ratios d'annulation, les scores de symétrie et le marketmaker_score\n",
    "ratios = []\n",
    "symmetry_scores = []\n",
    "marketmaker_scores = []\n",
    "action_counts = []  # Liste pour stocker le nombre d'actions de chaque subaccount\n",
    "\n",
    "# Boucle pour chaque subaccount\n",
    "for i in subaccount_num_mapping.keys():\n",
    "    subaccount = subaccount_num_mapping[i]\n",
    "    # Filtrer les ordres du subaccount\n",
    "    subaccount_orders = data[data[\"SubaccountID\"] == subaccount]\n",
    "    \n",
    "    # Calcul du ratio d'annulations\n",
    "    total_orders = len(subaccount_orders)\n",
    "    cancel_orders = len(subaccount_orders[subaccount_orders[\"Action\"] == \"EVENT_CANCEL\"])\n",
    "    ratio = cancel_orders / total_orders if total_orders > 0 else 0\n",
    "    ratios.append(ratio)\n",
    "    \n",
    "    # Calcul du score de symétrie\n",
    "    buy_orders = len(subaccount_orders[subaccount_orders[\"OrderType\"].isin([\"BUY\", \"BUY_PO\"])])\n",
    "    sell_orders = len(subaccount_orders[subaccount_orders[\"OrderType\"].isin([\"SELL\", \"SELL_PO\"])])\n",
    "    symmetry_score = ( buy_orders - sell_orders )\n",
    "    symmetry_scores.append(symmetry_score)\n",
    "    \n",
    "    # Calcul du nombre total d'actions (ordres) du subaccount\n",
    "    action_counts.append(total_orders)\n",
    "\n",
    "# Étape 2 : Normaliser les scores de symétrie entre 0 et 1\n",
    "symmetry_scores_normalized = (symmetry_scores - np.min(symmetry_scores)) / (np.max(symmetry_scores) - np.min(symmetry_scores))\n",
    "\n",
    "# Étape 3 : Calculer le marketmaker_score pour chaque subaccount en tenant compte du nombre d'actions\n",
    "for i in subaccount_num_mapping.keys():  \n",
    "    ratio = ratios[i]\n",
    "    symmetry_norm = symmetry_scores_normalized[i]\n",
    "    action_count = action_counts[i]\n",
    "    action_weight = action_count / max(action_counts)  # Normalisation par rapport au max du nombre d'actions\n",
    "    marketmaker_score = (2*ratio + 2*symmetry_norm + action_weight) / 5  # Moyenne des scores\n",
    "    marketmaker_scores.append((i,marketmaker_score))\n",
    "\n",
    "# Afficher les résultats\n",
    "for i in subaccount_num_mapping.keys():\n",
    "    subaccount=subaccount_num_mapping[i]\n",
    "    print(f\"Subaccount {i} ({subaccount}):\")\n",
    "    print(f\"  Ratio d'annulation = {ratios[i]:.2f}\")\n",
    "    print(f\"  Symmetry Score Normalisé = {symmetry_scores_normalized[i]:.2f}\")\n",
    "    print(f\"  Marketmaker Score = {marketmaker_scores[i][1]:.2f}\")\n",
    "    \n",
    "top_marketmakers = sorted(marketmaker_scores, key=lambda x: x[1],reverse=True)\n",
    "\n",
    "#We choose to consider only 2 marketmakers\n",
    "\n",
    "index_first=top_marketmakers[0][0]\n",
    "index_second=top_marketmakers[1][0]\n",
    "print(f\"Marketmaker #1: Subaccount {index_first} ({subaccount_num_mapping[index_first]}) with Marketmaker Score = {top_marketmakers[0][1]:.2f}\")\n",
    "print(f\"Marketmaker #2: Subaccount {index_second} ({subaccount_num_mapping[index_second]}) with Marketmaker Score = {top_marketmakers[1][1]:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subaccount 0 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000001):\n",
      "  Leverage Usage Normalisé = 1.00\n",
      "  Buy/Sell Skew Normalisé = 0.86\n",
      "  Leverage Seeker Score = 0.93\n",
      "Subaccount 1 (0x21596b451da15002ebbb91661f7f5e9f2f372343000000000000000000000011):\n",
      "  Leverage Usage Normalisé = 0.00\n",
      "  Buy/Sell Skew Normalisé = 0.97\n",
      "  Leverage Seeker Score = 0.49\n",
      "Subaccount 2 (0xed8c4c43e03e24b7f12975472da771ce2f8b857c000000000000000000000000):\n",
      "  Leverage Usage Normalisé = 0.00\n",
      "  Buy/Sell Skew Normalisé = 0.94\n",
      "  Leverage Seeker Score = 0.47\n",
      "Subaccount 3 (0xbcc871dab5a507624e55afeaa93610a424c446cc000000000000000000000000):\n",
      "  Leverage Usage Normalisé = 0.00\n",
      "  Buy/Sell Skew Normalisé = 0.98\n",
      "  Leverage Seeker Score = 0.49\n",
      "Subaccount 4 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000004):\n",
      "  Leverage Usage Normalisé = 0.02\n",
      "  Buy/Sell Skew Normalisé = 0.81\n",
      "  Leverage Seeker Score = 0.42\n",
      "Subaccount 5 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000003):\n",
      "  Leverage Usage Normalisé = 0.00\n",
      "  Buy/Sell Skew Normalisé = 0.97\n",
      "  Leverage Seeker Score = 0.49\n",
      "Subaccount 6 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000002):\n",
      "  Leverage Usage Normalisé = 0.03\n",
      "  Buy/Sell Skew Normalisé = 0.99\n",
      "  Leverage Seeker Score = 0.51\n",
      "Subaccount 7 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000002):\n",
      "  Leverage Usage Normalisé = 0.09\n",
      "  Buy/Sell Skew Normalisé = 1.00\n",
      "  Leverage Seeker Score = 0.55\n",
      "Subaccount 8 (0x7cf40a60c390723ec2d34c2fef23314d830eed22000000000000000000000000):\n",
      "  Leverage Usage Normalisé = 0.12\n",
      "  Buy/Sell Skew Normalisé = 1.00\n",
      "  Leverage Seeker Score = 0.56\n",
      "Subaccount 9 (0x31307ef22c77cc89cd7e61246608f15b82d09fed000000000000000000000001):\n",
      "  Leverage Usage Normalisé = 0.13\n",
      "  Buy/Sell Skew Normalisé = 0.96\n",
      "  Leverage Seeker Score = 0.55\n",
      "Subaccount 10 (0xe5b451c363197d375904ec167d8ed10b7bbd1e63000000000000000000000002):\n",
      "  Leverage Usage Normalisé = 0.02\n",
      "  Buy/Sell Skew Normalisé = 0.85\n",
      "  Leverage Seeker Score = 0.44\n",
      "Subaccount 11 (0xe254824846257f132fdcac1115c4ca9fead4f47c000000000000000000000000):\n",
      "  Leverage Usage Normalisé = 0.26\n",
      "  Buy/Sell Skew Normalisé = 0.00\n",
      "  Leverage Seeker Score = 0.13\n"
     ]
    }
   ],
   "source": [
    "#IDENTIFY DEGEN LEVERAGE SEEKERS\n",
    "\n",
    "# Étape 1 : Extraire les 12 premiers subaccounts (numérotés de 0 à 11)\n",
    "subaccounts = data[\"SubaccountID\"].unique()[:12]\n",
    "\n",
    "# Initialiser les listes pour les métriques\n",
    "leverage_usages = []\n",
    "buy_sell_skews = []\n",
    "leverage_seeker_scores = []\n",
    "\n",
    "# Boucle pour chaque subaccount\n",
    "for i in subaccount_num_mapping.keys():\n",
    "    # Filtrer les ordres du subaccount\n",
    "    subaccount_orders = data[data[\"SubaccountID\"] == subaccount]\n",
    "    subaccount= subaccount_num_mapping[i]\n",
    "    \n",
    "    # Calcul de l'utilisation de la \"marge\" comme proxy basé sur la taille de l'ordre\n",
    "    total_order_values = subaccount_orders[\"Quantity\"] * subaccount_orders[\"Price\"]\n",
    "    avg_order_value = total_order_values.mean() if not total_order_values.empty else 0\n",
    "    leverage_usage = avg_order_value / total_order_values.sum() if total_order_values.sum() > 0 else 0\n",
    "    leverage_usages.append(leverage_usage)\n",
    "    \n",
    "    # Calcul du déséquilibre achat/vente\n",
    "    buy_orders = len(subaccount_orders[subaccount_orders[\"OrderType\"].isin([\"BUY\", \"BUY_PO\"])])\n",
    "    sell_orders = len(subaccount_orders[subaccount_orders[\"OrderType\"].isin([\"SELL\", \"SELL_PO\"])])\n",
    "    buy_sell_skew = 1- abs(buy_orders - sell_orders) / (buy_orders + sell_orders) if (buy_orders + sell_orders) > 0 else 0\n",
    "    buy_sell_skews.append(buy_sell_skew)\n",
    "\n",
    "# Étape 2 : Normaliser les métriques entre 0 et 1\n",
    "leverage_usages_normalized = (leverage_usages - np.min(leverage_usages)) / (np.max(leverage_usages) - np.min(leverage_usages))\n",
    "buy_sell_skews_normalized = (buy_sell_skews - np.min(buy_sell_skews)) / (np.max(buy_sell_skews) - np.min(buy_sell_skews))\n",
    "\n",
    "# Étape 3 : Calculer le score \"degen leverage seeker\" pour chaque subaccount\n",
    "for i in subaccount_num_mapping.keys():\n",
    "    leverage_norm = leverage_usages_normalized[i]\n",
    "    skew_norm = buy_sell_skews_normalized[i]\n",
    "    leverage_seeker_score = (leverage_norm + skew_norm) / 2  # Moyenne des deux scores normalisés\n",
    "    leverage_seeker_scores.append((i,leverage_seeker_score))\n",
    "\n",
    "# Afficher les résultats\n",
    "for i in subaccount_num_mapping.keys():\n",
    "    subaccount=subaccount_num_mapping[i]\n",
    "    print(f\"Subaccount {i} ({subaccount}):\")\n",
    "    print(f\"  Leverage Usage Normalisé = {leverage_usages_normalized[i]:.2f}\")\n",
    "    print(f\"  Buy/Sell Skew Normalisé = {buy_sell_skews_normalized[i]:.2f}\")\n",
    "    print(f\"  Leverage Seeker Score = {leverage_seeker_scores[i][1]:.2f}\")\n",
    "\n",
    "top_leverage_seekers = sorted(enumerate(leverage_seeker_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subaccount 0 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000001):\n",
      "  Average Holding Time = 746.83 blocks\n",
      "  Average Orders per Block = 2.02\n",
      "  Scalper Score = 0.57\n",
      "Subaccount 1 (0x21596b451da15002ebbb91661f7f5e9f2f372343000000000000000000000011):\n",
      "  Average Holding Time = 758.84 blocks\n",
      "  Average Orders per Block = 2.46\n",
      "  Scalper Score = 0.61\n",
      "Subaccount 2 (0xed8c4c43e03e24b7f12975472da771ce2f8b857c000000000000000000000000):\n",
      "  Average Holding Time = 733.31 blocks\n",
      "  Average Orders per Block = 4.32\n",
      "  Scalper Score = 0.77\n",
      "Subaccount 3 (0xbcc871dab5a507624e55afeaa93610a424c446cc000000000000000000000000):\n",
      "  Average Holding Time = 785.02 blocks\n",
      "  Average Orders per Block = 1.17\n",
      "  Scalper Score = 0.50\n",
      "Subaccount 4 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000004):\n",
      "  Average Holding Time = 770.18 blocks\n",
      "  Average Orders per Block = 2.98\n",
      "  Scalper Score = 0.66\n",
      "Subaccount 5 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000003):\n",
      "  Average Holding Time = 745.94 blocks\n",
      "  Average Orders per Block = 2.31\n",
      "  Scalper Score = 0.60\n",
      "Subaccount 6 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000002):\n",
      "  Average Holding Time = 702.18 blocks\n",
      "  Average Orders per Block = 1.19\n",
      "  Scalper Score = 0.50\n",
      "Subaccount 7 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000002):\n",
      "  Average Holding Time = 745.12 blocks\n",
      "  Average Orders per Block = 3.33\n",
      "  Scalper Score = 0.69\n",
      "Subaccount 8 (0x7cf40a60c390723ec2d34c2fef23314d830eed22000000000000000000000000):\n",
      "  Average Holding Time = 725.50 blocks\n",
      "  Average Orders per Block = 2.16\n",
      "  Scalper Score = 0.59\n",
      "Subaccount 9 (0x31307ef22c77cc89cd7e61246608f15b82d09fed000000000000000000000001):\n",
      "  Average Holding Time = 448.06 blocks\n",
      "  Average Orders per Block = 2.13\n",
      "  Scalper Score = 0.58\n",
      "Subaccount 10 (0xe5b451c363197d375904ec167d8ed10b7bbd1e63000000000000000000000002):\n",
      "  Average Holding Time = inf blocks\n",
      "  Average Orders per Block = 2.08\n",
      "  Scalper Score = nan\n",
      "Subaccount 11 (0xe254824846257f132fdcac1115c4ca9fead4f47c000000000000000000000000):\n",
      "  Average Holding Time = 0.00 blocks\n",
      "  Average Orders per Block = 7.00\n",
      "  Scalper Score = 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\AppData\\Local\\Temp\\ipykernel_11980\\634623191.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  holding_times_normalized = (1 - (holding_times - np.min(holding_times)) / (np.max(holding_times) - np.min(holding_times)))\n"
     ]
    }
   ],
   "source": [
    "    #IDENTIFY SCALPERS\n",
    "\n",
    "    # Initialiser les listes pour les ratios, les scores et le scalper_score\n",
    "    holding_times = []\n",
    "    order_frequencies = []\n",
    "    scalper_scores = []\n",
    "\n",
    "    # Boucle pour chaque subaccount\n",
    "    for i in subaccount_num_mapping.keys():\n",
    "        subaccount=subaccount_num_mapping[i]\n",
    "        # Filtrer les ordres du subaccount\n",
    "        subaccount_orders = data[data[\"SubaccountID\"] == subaccount]\n",
    "        \n",
    "        # Filtrer les ordres d'achat et de vente\n",
    "        buy_orders = subaccount_orders[subaccount_orders[\"OrderType\"].isin([\"BUY\", \"BUY_PO\"])]\n",
    "        sell_orders = subaccount_orders[subaccount_orders[\"OrderType\"].isin([\"SELL\", \"SELL_PO\"])]\n",
    "        \n",
    "        # Calculer le temps moyen de détention (différence entre le bloc d'achat et le bloc de vente)\n",
    "        if not buy_orders.empty and not sell_orders.empty:\n",
    "            avg_holding_time = np.mean([\n",
    "                sell_block - buy_block\n",
    "                for buy_block in buy_orders[\"Block\"]\n",
    "                for sell_block in sell_orders[\"Block\"]\n",
    "                if sell_block >= buy_block\n",
    "            ])\n",
    "        else:\n",
    "            avg_holding_time = float('inf')  # Aucun ordre d'achat/vente pairé\n",
    "        \n",
    "        holding_times.append(avg_holding_time)\n",
    "        \n",
    "        # Calculer la fréquence des ordres par bloc\n",
    "        orders_per_block = subaccount_orders.groupby(\"Block\").size()\n",
    "        avg_orders_per_block = orders_per_block.mean()  # Moyenne des ordres par bloc\n",
    "        order_frequencies.append(avg_orders_per_block)\n",
    "        \n",
    "    # Étape 2 : Normaliser les scores entre 0 et 1\n",
    "    holding_times_normalized = (1 - (holding_times - np.min(holding_times)) / (np.max(holding_times) - np.min(holding_times)))\n",
    "    order_frequencies_normalized = (order_frequencies - np.min(order_frequencies)) / (np.max(order_frequencies) - np.min(order_frequencies))\n",
    "\n",
    "    # Étape 3 : Calculer le scalper_score pour chaque subaccount\n",
    "    for i in subaccount_num_mapping.keys():\n",
    "        holding_time_norm = holding_times_normalized[i]\n",
    "        order_freq_norm = order_frequencies_normalized[i]\n",
    "        scalper_score = (holding_time_norm + order_freq_norm) / 2  # Moyenne des deux scores normalisés\n",
    "        scalper_scores.append((i,scalper_score))\n",
    "\n",
    "    # Afficher les résultats\n",
    "    for i in subaccount_num_mapping.keys():\n",
    "        subaccount=subaccount_num_mapping[i]\n",
    "        print(f\"Subaccount {i} ({subaccount}):\")\n",
    "        print(f\"  Average Holding Time = {holding_times[i]:.2f} blocks\")\n",
    "        print(f\"  Average Orders per Block = {order_frequencies[i]:.2f}\")\n",
    "        print(f\"  Scalper Score = {scalper_scores[i][1]:.2f}\")\n",
    "\n",
    "    # Trouver les top scalpers\n",
    "    top_scalpers = sorted(enumerate(scalper_scores), key=lambda x: x[1], reverse=True)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subaccount 0 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000001):\n",
      "  Taille moyenne des ordres normalisée = 0.02\n",
      "  Nombre d'ordres (inverse normalisé) = 0.46\n",
      "  Swing Trader Score = 0.16\n",
      "Subaccount 1 (0x21596b451da15002ebbb91661f7f5e9f2f372343000000000000000000000011):\n",
      "  Taille moyenne des ordres normalisée = 0.03\n",
      "  Nombre d'ordres (inverse normalisé) = 0.13\n",
      "  Swing Trader Score = 0.06\n",
      "Subaccount 2 (0xed8c4c43e03e24b7f12975472da771ce2f8b857c000000000000000000000000):\n",
      "  Taille moyenne des ordres normalisée = 0.13\n",
      "  Nombre d'ordres (inverse normalisé) = 0.00\n",
      "  Swing Trader Score = 0.09\n",
      "Subaccount 3 (0xbcc871dab5a507624e55afeaa93610a424c446cc000000000000000000000000):\n",
      "  Taille moyenne des ordres normalisée = 0.07\n",
      "  Nombre d'ordres (inverse normalisé) = 0.95\n",
      "  Swing Trader Score = 0.36\n",
      "Subaccount 4 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000004):\n",
      "  Taille moyenne des ordres normalisée = 0.44\n",
      "  Nombre d'ordres (inverse normalisé) = 0.32\n",
      "  Swing Trader Score = 0.40\n",
      "Subaccount 5 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000003):\n",
      "  Taille moyenne des ordres normalisée = 1.00\n",
      "  Nombre d'ordres (inverse normalisé) = 0.96\n",
      "  Swing Trader Score = 0.99\n",
      "Subaccount 6 (0x5303d92e49a619bb29de8fb6f59c0e7589213cc8000000000000000000000002):\n",
      "  Taille moyenne des ordres normalisée = 0.00\n",
      "  Nombre d'ordres (inverse normalisé) = 0.99\n",
      "  Swing Trader Score = 0.33\n",
      "Subaccount 7 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000002):\n",
      "  Taille moyenne des ordres normalisée = 0.00\n",
      "  Nombre d'ordres (inverse normalisé) = 0.99\n",
      "  Swing Trader Score = 0.33\n",
      "Subaccount 8 (0x7cf40a60c390723ec2d34c2fef23314d830eed22000000000000000000000000):\n",
      "  Taille moyenne des ordres normalisée = 0.14\n",
      "  Nombre d'ordres (inverse normalisé) = 0.99\n",
      "  Swing Trader Score = 0.42\n",
      "Subaccount 9 (0x31307ef22c77cc89cd7e61246608f15b82d09fed000000000000000000000001):\n",
      "  Taille moyenne des ordres normalisée = 0.01\n",
      "  Nombre d'ordres (inverse normalisé) = 0.95\n",
      "  Swing Trader Score = 0.32\n",
      "Subaccount 10 (0xe5b451c363197d375904ec167d8ed10b7bbd1e63000000000000000000000002):\n",
      "  Taille moyenne des ordres normalisée = 0.05\n",
      "  Nombre d'ordres (inverse normalisé) = 1.00\n",
      "  Swing Trader Score = 0.37\n",
      "Subaccount 11 (0xe254824846257f132fdcac1115c4ca9fead4f47c000000000000000000000000):\n",
      "  Taille moyenne des ordres normalisée = 0.00\n",
      "  Nombre d'ordres (inverse normalisé) = 1.00\n",
      "  Swing Trader Score = 0.33\n",
      "\n",
      "Swing Trader #1: Subaccount 5 (0x45413d9cb161b88099123c31c720e57f276b8f2b000000000000000000000003) avec un score de 0.99\n",
      "Swing Trader #2: Subaccount 8 (0x7cf40a60c390723ec2d34c2fef23314d830eed22000000000000000000000000) avec un score de 0.42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger les données du fichier CSV\n",
    "# Remplacez 'orders.csv' par le chemin de votre fichier CSV\n",
    "orders_data = pd.read_csv(\"orders.csv\")\n",
    "\n",
    "# Initialisation des listes pour les métriques\n",
    "average_order_sizes = []\n",
    "total_order_counts = []\n",
    "swing_trader_scores = []\n",
    "\n",
    "# Identifier les subaccounts uniques\n",
    "subaccounts = orders_data[\"SubaccountID\"].unique()\n",
    "\n",
    "# Boucle pour chaque subaccount\n",
    "for subaccount in subaccounts:\n",
    "    # Filtrer les ordres du subaccount\n",
    "    subaccount_orders = orders_data[orders_data[\"SubaccountID\"] == subaccount]\n",
    "\n",
    "    # Calcul de la taille moyenne des ordres\n",
    "    total_order_sizes = subaccount_orders[\"Quantity\"] * subaccount_orders[\"Price\"]\n",
    "    average_order_size = total_order_sizes.mean() if not total_order_sizes.empty else 0\n",
    "    average_order_sizes.append(average_order_size)\n",
    "\n",
    "    # Calcul du nombre total d'ordres\n",
    "    total_orders = len(subaccount_orders)\n",
    "    total_order_counts.append(total_orders)\n",
    "\n",
    "# Étape 1 : Normaliser les tailles moyennes et les nombres d'ordres entre 0 et 1\n",
    "average_order_sizes_normalized = (average_order_sizes - np.min(average_order_sizes)) / (np.max(average_order_sizes) - np.min(average_order_sizes))\n",
    "total_order_counts_normalized = (total_order_counts - np.min(total_order_counts)) / (np.max(total_order_counts) - np.min(total_order_counts))\n",
    "\n",
    "# Étape 2 : Calculer le score de swing trader pour chaque subaccount\n",
    "for i, subaccount in enumerate(subaccounts):\n",
    "    # Critères : faible nombre d'ordres et grande taille moyenne des ordres\n",
    "    order_size_norm = average_order_sizes_normalized[i]\n",
    "    order_count_norm = 1 - total_order_counts_normalized[i]  # Inverser pour privilégier un faible nombre d'ordres\n",
    "    swing_trader_score = (2 * order_size_norm + order_count_norm) / 3  # Moyenne pondérée\n",
    "    swing_trader_scores.append((i, swing_trader_score))\n",
    "\n",
    "# Afficher les résultats\n",
    "for i, subaccount in enumerate(subaccounts):\n",
    "    print(f\"Subaccount {i} ({subaccount}):\")\n",
    "    print(f\"  Taille moyenne des ordres normalisée = {average_order_sizes_normalized[i]:.2f}\")\n",
    "    print(f\"  Nombre d'ordres (inverse normalisé) = {1 - total_order_counts_normalized[i]:.2f}\")\n",
    "    print(f\"  Swing Trader Score = {swing_trader_scores[i][1]:.2f}\")\n",
    "\n",
    "# Identifier les meilleurs swing traders\n",
    "top_swing_traders = sorted(swing_trader_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Afficher les 2 swing traders les plus probables\n",
    "index_first = top_swing_traders[0][0]\n",
    "index_second = top_swing_traders[1][0]\n",
    "print(f\"\\nSwing Trader #1: Subaccount {index_first} ({subaccounts[index_first]}) avec un score de {top_swing_traders[0][1]:.2f}\")\n",
    "print(f\"Swing Trader #2: Subaccount {index_second} ({subaccounts[index_second]}) avec un score de {top_swing_traders[1][1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialisation du temps\n",
    "start = time.time()\n",
    "\n",
    "# Étape 1 : Chargement et nettoyage des données\n",
    "def load_and_clean_data(filepath):\n",
    "    # Lecture du fichier CSV\n",
    "    file_path = \"orders.csv\"  # Remplace par le chemin réel de ton fichier\n",
    "    columns = [\"OrderHash\", \"Block\", \"Action\", \"Price\", \"Quantity\", \"OrderType\", \"SubaccountID\"]\n",
    "    df = pd.read_csv(file_path, names=columns, skiprows=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Étape 2 : Identifier des liens d'influence\n",
    "def detect_influence_links(df, time_window=60):\n",
    "    # Liste pour stocker les liens d'influence\n",
    "    influence_links = []\n",
    "\n",
    "    # Trier les données par bloc et sous-compte\n",
    "    df = df.sort_values(by=['Block', 'SubaccountID'])\n",
    "\n",
    "    # On nomme les comptes avec leur numéro d'apparition\n",
    "    accounts = {}\n",
    "    numero = 0\n",
    "\n",
    "    # Permet de connaître qui a agit sur le bloc courant\n",
    "    actions_on_block = [0 for _ in range(df[\"SubaccountID\"].nunique())]\n",
    "    block_number = 0\n",
    "\n",
    "    # Calculer les différences de blocs entre les actions\n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        # Si changement de block, on enregistre les acteurs du block dans la matrice\n",
    "        if row['Block'] != block_number :\n",
    "            block_number = row['Block']\n",
    "            influence_links.append(actions_on_block)\n",
    "            actions_on_block = [0 for _ in range(df[\"SubaccountID\"].nunique())]\n",
    "\n",
    "        # On nomme les comptes pas visités\n",
    "        if row['SubaccountID'] not in accounts :\n",
    "            accounts[row['SubaccountID']] = numero\n",
    "            numero += 1\n",
    "        \n",
    "        # On enregistre l'acteur sur le block courant\n",
    "        actions_on_block[accounts[row['SubaccountID']]] = 1\n",
    "\n",
    "    # Retourner les liens d'influence détectés\n",
    "    return np.array(influence_links)\n",
    "\n",
    "\n",
    "def graphe(actions_simultanees) :\n",
    "\n",
    "    # Étape 3.1 : Construction du réseau d'interactions\n",
    "    # Graphique des influences\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Ajouter des nœuds pour chaque SubaccountID unique\n",
    "    subaccounts = []\n",
    "    for k in range(len(actions_simultanees)) :\n",
    "        subaccounts.append(k)\n",
    "    G.add_nodes_from(subaccounts)\n",
    "\n",
    "    # On ajoute les arêtes d'influences avec leur poids entre les comptes\n",
    "    for i in range(len(actions_simultanees)) :\n",
    "        for j in range(len(actions_simultanees[0])) :\n",
    "            if actions_simultanees[i][j] != 0 :\n",
    "                G.add_edge(i, j, weight=actions_simultanees[i][j])\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "# Exemple d'exécution\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"orders.csv\"  # Remplacez par le chemin de votre fichier\n",
    "\n",
    "    # Étape 1 : Chargement et nettoyage des données\n",
    "    df_clean = load_and_clean_data(filepath)\n",
    "    \n",
    "    # Étape 2 : Détection des liens d'influence\n",
    "    influence_links = detect_influence_links(df_clean)\n",
    "\n",
    "\n",
    "    actions_simultanees = influence_links.T @ influence_links\n",
    "\n",
    "\n",
    "    graphe(actions_simultanees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation terminée et sauvegardée sous simulated_order_book.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Définition des classes de traders ---\n",
    "class Trader:\n",
    "    def __init__(self, unique_id, profile):\n",
    "        self.unique_id = unique_id\n",
    "        self.profile = profile\n",
    "        self.position = \"NEUTRAL\"\n",
    "\n",
    "    def decide_action(self, market_price):\n",
    "        \"\"\"Détermine l'action du trader en fonction du profil et du prix du marché.\"\"\"\n",
    "        raise NotImplementedError(\"Cette méthode doit être implémentée par les sous-classes.\")\n",
    "\n",
    "class MarketMaker(Trader):\n",
    "    def decide_action(self, market_price):\n",
    "        if random.random() < 0.7:\n",
    "            return \"BUY\" if random.random() < 0.5 else \"SELL\"\n",
    "        if random.random() < 0.3:\n",
    "            return \"BUY_CANCEL\" if random.random() < 0.5 else \"SELL_CANCEL\"\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "class Degen(Trader):\n",
    "    def decide_action(self, market_price):\n",
    "        if random.random() < 0.6:\n",
    "            return \"BUY\" if random.random() < 0.5 else \"SELL\"\n",
    "        if random.random() < 0.2:\n",
    "            return \"BUY_CANCEL\" if random.random() < 0.5 else \"SELL_CANCEL\"\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "class Scalper(Trader):\n",
    "    def decide_action(self, market_price):\n",
    "        if random.random() < 0.8:\n",
    "            return \"BUY\" if random.random() < 0.5 else \"SELL\"\n",
    "        if random.random() < 0.4:\n",
    "            return \"BUY_CANCEL\" if random.random() < 0.5 else \"SELL_CANCEL\"\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "class NoiseTrader(Trader):\n",
    "    def decide_action(self, market_price):\n",
    "        return random.choice([\"BUY\", \"SELL\", \"BUY_CANCEL\", \"SELL_CANCEL\", \"NEUTRAL\"])\n",
    "\n",
    "class SwingTrader(Trader):\n",
    "    def decide_action(self, market_price):\n",
    "        if random.random() < 0.4:\n",
    "            return \"BUY\" if random.random() < 0.5 else \"SELL\"\n",
    "        if random.random() < 0.2:\n",
    "            return \"BUY_CANCEL\" if random.random() < 0.5 else \"SELL_CANCEL\"\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "# --- Paramètres de simulation ---\n",
    "num_traders = 100\n",
    "num_steps = 50\n",
    "initial_price = 50000  # Prix initial du BTC\n",
    "volatility = 0.02  # Volatilité simulée\n",
    "\n",
    "# Répartition des profils\n",
    "trader_profiles = {\n",
    "    \"Market Maker\": MarketMaker,\n",
    "    \"Degen\": Degen,\n",
    "    \"Scalper\": Scalper,\n",
    "    \"Noise\": NoiseTrader,\n",
    "    \"Swing Trader\": SwingTrader\n",
    "}\n",
    "\n",
    "# Création des traders\n",
    "traders = []\n",
    "for i in range(num_traders):\n",
    "    profile = random.choice(list(trader_profiles.keys()))\n",
    "    traders.append(trader_profiles[profile](i, profile))\n",
    "\n",
    "# Structure de l'order book\n",
    "order_book = {\n",
    "    \"OrderHash\": [],\n",
    "    \"Block\": [],\n",
    "    \"Action\": [],\n",
    "    \"Price\": [],\n",
    "    \"Quantity\": [],\n",
    "    \"OrderType\": [],\n",
    "    \"Subaccount\": []\n",
    "}\n",
    "\n",
    "# --- Simulation ---\n",
    "market_price = initial_price\n",
    "\n",
    "for step in range(num_steps):\n",
    "    total_volume = 0  # Volume total échangé à cette étape\n",
    "    \n",
    "    for trader in traders:\n",
    "        action = trader.decide_action(market_price)\n",
    "\n",
    "        if action != \"NEUTRAL\":\n",
    "            hash_id = hex(random.randint(0, 1000000000))\n",
    "            price = round(market_price * (1 + random.uniform(-0.001, 0.001)), 2)\n",
    "            quantity = random.randint(1, 10)\n",
    "\n",
    "            order_book[\"OrderHash\"].append(hash_id)\n",
    "            order_book[\"Block\"].append(step)\n",
    "            order_book[\"Action\"].append(\"EVENT_NEW\")\n",
    "            order_book[\"Price\"].append(price)\n",
    "            order_book[\"Quantity\"].append(quantity)\n",
    "            order_book[\"OrderType\"].append(action)\n",
    "            order_book[\"Subaccount\"].append(trader.unique_id)\n",
    "\n",
    "            if action in [\"BUY\", \"SELL\"]:\n",
    "                total_volume += quantity\n",
    "\n",
    "    # Mise à jour du prix du BTC avec la loi de diffusion racine carrée\n",
    "    delta_price = volatility * np.sqrt(total_volume) * random.choice([-1, 1])\n",
    "    market_price = max(1000, market_price + delta_price)  # Prix >= 1000\n",
    "\n",
    "# --- Sauvegarde en CSV ---\n",
    "df_orders = pd.DataFrame(order_book)\n",
    "df_orders.to_csv(\"order_book_simulated.csv\", index=False)\n",
    "\n",
    "print(\"Simulation terminée. Order book sauvegardé sous 'order_book_simulated.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
